{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mnist.target = pd.get_dummies(mnist.target).astype(int).values\n",
    "mnist.data = mnist.data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 11s - loss: 0.6936    \n",
      "Train on 42000 samples, validate on 28000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.4906 - acc: 0.8641 - val_loss: 0.3086 - val_acc: 0.9103\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.2710 - acc: 0.9222 - val_loss: 0.2538 - val_acc: 0.9264\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.2267 - acc: 0.9355 - val_loss: 0.2287 - val_acc: 0.9342\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.2003 - acc: 0.9444 - val_loss: 0.2070 - val_acc: 0.9406\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1811 - acc: 0.9491 - val_loss: 0.1968 - val_acc: 0.9427\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1650 - acc: 0.9534 - val_loss: 0.1929 - val_acc: 0.9441\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1531 - acc: 0.9557 - val_loss: 0.1779 - val_acc: 0.9490\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1418 - acc: 0.9589 - val_loss: 0.1759 - val_acc: 0.9484\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1324 - acc: 0.9623 - val_loss: 0.1635 - val_acc: 0.9526\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 2s - loss: 0.1247 - acc: 0.9654 - val_loss: 0.1619 - val_acc: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc67c88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "\n",
    "# pretrain the first layer using an autoencoder\n",
    "encoding_dim = 32\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                nb_epoch=1,\n",
    "                batch_size=256,\n",
    "                shuffle=True)\n",
    "\n",
    "classifier = Dense(10, activation='softmax')(encoded)\n",
    "model = Model(input=input_img, output=classifier)\n",
    "\n",
    "from keras import optimizers\n",
    "optimizer = optimizers.SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
